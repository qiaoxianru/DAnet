# DAnet
DANet: Enhancing Image Classification with Direction-Aware Attention and Neural Signal Attenuation
abstract:Attention mechanisms have become pivotal in advancing convolutional neural networks for image classification through feature selection and enhancement. However, existing methods often overlook two synergistic characteristics of the biological visual system: its acute sensitivity to directional features and its nonlinear inhibitory mechanisms for filtering non-critical information. This oversight limits the effective extraction of multi-oriented structures and leads to imbalanced channel responses under noisy conditions. Inspired by these principles, we propose a Direction-aware Attention Network (DANet). Its core is a novel Direction-aware Attention (DA) module that integrates a direction-aware convolution (DAConv) with a two-stage neural signal attenuation mechanism. DAConv systematically captures local spatial details along horizontal, vertical, main diagonal, and anti-diagonal orientations. The subsequent two-stage attenuation adaptively smooths and recalibrates channel weights, suppressing noise and extreme activations while promoting a balanced feature distribution. Embedded within residual blocks to form DA-blocks, this design mitigates the loss of critical features in deep layers. Extensive experiments on CIFAR-10, CIFAR-100, SVHN, Imagenette, and Imagewoof datasets demonstrate that DANet achieves superior classification accuracy. For instance, it attains 96.76\% on CIFAR-10 and 90.93\% on Imagenette, outperforming ResNet-34 and other attention-based benchmarks. The synergy between directional feature extraction and adaptive attenuation enhances the model's robustness and spatial structure discrimination, offering a more biologically plausible pathway for advancing feature representation in computer vision.
