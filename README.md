# DAnet
## DANet: Enhancing Image Classification with Direction-Aware Attention and Neural Signal Attenuation
abstract:Attention mechanisms have become pivotal in advancing convolutional neural networks for image classification through feature selection and enhancement. However, existing methods often overlook two synergistic characteristics of the biological visual system: its acute sensitivity to directional features and its nonlinear inhibitory mechanisms for filtering non-critical information. This oversight limits the effective extraction of multi-oriented structures and leads to imbalanced channel responses under noisy conditions. Inspired by these principles, we propose a Direction-aware Attention Network (DANet). Its core is a novel Direction-aware Attention (DA) module that integrates a direction-aware convolution (DAConv) with a two-stage neural signal attenuation mechanism. DAConv systematically captures local spatial details along horizontal, vertical, main diagonal, and anti-diagonal orientations. The subsequent two-stage attenuation adaptively smooths and recalibrates channel weights, suppressing noise and extreme activations while promoting a balanced feature distribution. Embedded within residual blocks to form DA-blocks, this design mitigates the loss of critical features in deep layers. Extensive experiments on CIFAR-10, CIFAR-100, SVHN, Imagenette, and Imagewoof datasets demonstrate that DANet achieves superior classification accuracy. For instance, it attains 96.76\% on CIFAR-10 and 90.93\% on Imagenette, outperforming ResNet-34 and other attention-based benchmarks. The synergy between directional feature extraction and adaptive attenuation enhances the model's robustness and spatial structure discrimination, offering a more biologically plausible pathway for advancing feature representation in computer vision.
## Experimental Environment
The operating system used in the experiment is Linux 6.6.56. The required hardware environment parameters are NVIDIA Tesla P100 graphics cards and 60GB of memory. The software environment consists of PyTorch 2.6.0, CUDA 12.4, and CUDNN 8=9.0.3. The programming language is Python 3.11.11. 
This experiment employs classification accuracy as the evaluation metric for image classification. During training, the iteration count is set to 200 epochs, utilizing the Stochastic Gradient Descent (SGD) optimizer with label smoothing of 0.1, momentum of 0.9, weight decay of 5×10⁻⁴, and a learning rate of 0.1. Data augmentation during training included random flipping, random cropping after padding, and random erasure. Input image dimensions were adjusted to 32×32 pixels for the CIFAR-10, CIFAR-100 and SVHN datasets, with a batch size of 128. For the Imagenette and Imagewoof datasets, input dimensions were set to 224×224 pixels with a batch size of 64.
