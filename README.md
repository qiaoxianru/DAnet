# DAnet
Direction-aware Attention for Image Classification
abstract:Attention mechanisms have demonstrated efficacy in feature selection and enhancement for image classification, establishing themselves as a pivotal technique for advancing convolutional neural networks. However, the majority of extant methods neglect the fact that the biological visual system tends to focus more on processing directional features of objects, while also exhibiting nonlinear inhibitory effects on the perception of specific objects. To this end, we report a Direction-aware Attention Network for Image Classification (DANet). Specifically, we present a Direction-aware Attention (DA) module. The module first incorporates a direction-aware convolution, which we term DAConv. It utilizes directional convolution operations in horizontal, vertical, main diagonal, and anti-diagonal orientations to capture multi-directional local spatial details and contextual information in images systematically, thereby improving the model's perception of directional features. Subsequently, the DA module incorporates an innovative two-stage neural signal attenuation mechanism, which we term two-stage attenuation. Adaptively smoothing and attenuating feature responses suppresses extreme values and noise in attention weights effectively, and promotes a balanced distribution of channel responses. Ultimately, through embedding the DA module into residual blocks to form DA-blocks, the network reduces the loss of critical features in deeper layers while strengthening its capacity to learn multi-directional spatial features and contextual relationships. Extensive experiments on several datasets demonstrate that our method achieves significantly higher classification accuracy. The network enhances directional feature extraction and noise suppression through DAConv and two-stage attenuation, improving spatial detail perception and classification performance in complex scenarios.
