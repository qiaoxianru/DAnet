{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pdb\nimport argparse\nfrom tqdm import tqdm\nimport math\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\nfrom torch.optim.lr_scheduler import MultiStepLR\n\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets, transforms\n\n\nclass Cutout(object):\n    \"\"\"Randomly mask out one or more patches from an image.\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    \"\"\"\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        \"\"\"\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        \"\"\"\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length // 2, 0, h)\n            y2 = np.clip(y + self.length // 2, 0, h)\n            x1 = np.clip(x - self.length // 2, 0, w)\n            x2 = np.clip(x + self.length // 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n\n\nclass DynamicDecay(nn.Module):\n    def __init__(self, decay_factor):\n        super(DynamicDecay, self).__init__()\n        self.decay_factor = decay_factor\n\n    def forward(self, x):\n        return x * torch.exp(-torch.abs(x/self.decay_factor))\n\n\nclass FourDirectionAttention(nn.Module):\n    def __init__(self, channel, reduction=16, conv_kernel=5):\n        super(FourDirectionAttention, self).__init__()\n        \n        \n        self.h_conv = nn.Conv2d(channel, channel, (conv_kernel, 3),\n                              padding=(conv_kernel//2, 1), groups=channel)\n       \n        self.w_conv = nn.Conv2d(channel, channel, (3, conv_kernel),\n                              padding=(1, conv_kernel//2), groups=channel)\n        \n        self.diag1_conv = nn.Conv2d(channel, channel, conv_kernel,\n                                   padding=conv_kernel//2, groups=channel)\n        \n        self.diag2_conv = nn.Conv2d(channel, channel, conv_kernel,\n                                   padding=conv_kernel//2, groups=channel)\n        \n        \n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.mlp = nn.Sequential(\n            nn.Linear(channel, channel//reduction),\n            DynamicDecay(6.0),  # 第一次衰减\n            nn.Linear(channel//reduction, channel),\n            nn.Sigmoid()\n        )\n        self.final_decay = DynamicDecay(2.0)  # 第二次衰减\n        \n    def forward(self, x):\n        # 四个方向的特征融合\n        h_feat = self.h_conv(x)  \n        w_feat = self.w_conv(x)  \n        \n        \n        diag1_feat = self.diag1_conv(x)\n        \n        \n        x_rot = torch.rot90(x, 1, [2, 3])  \n        diag2_feat = self.diag2_conv(x_rot)\n        diag2_feat = torch.rot90(diag2_feat, -1, [2, 3])  \n        \n        # 融合四个方向的特征\n        x_mixed = x + h_feat + w_feat + diag1_feat + diag2_feat\n        \n        # 注意力计算\n        b, c, _, _ = x_mixed.size()\n        att = self.gap(x_mixed).view(b, c)\n        att = self.mlp(att)\n        att = self.final_decay(att)\n        \n        return x * att.view(b, c, 1, 1)\n\n# ResNet\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.attention = FourDirectionAttention(planes)  \n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.attention(out) \n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = conv3x3(3,64)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18(num_classes=10):\n    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n\ndef ResNet34(num_classes=10):\n    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n\ndef ResNet50(num_classes=10):\n    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n\ndef ResNet101(num_classes=10):\n    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n\ndef ResNet152(num_classes=10):\n    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n\ndef test_resnet():\n    net = ResNet50()\n    y = net(Variable(torch.randn(1,3,32,32)))\n    print(y.size())\nn_holes = 1\nlength = 19\nbatch_size = 128\nlearning_rate = 0.1\nnormalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n\ntrain_transform = transforms.Compose([])\ntrain_transform.transforms.append(transforms.RandomCrop(32, padding=4))\ntrain_transform.transforms.append(transforms.RandomHorizontalFlip())\ntrain_transform.transforms.append(transforms.ToTensor())\ntrain_transform.transforms.append(normalize)\ntrain_transform.transforms.append(Cutout(n_holes = n_holes, length = length))\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    normalize])\n\n# num_classes = 10\n# train_dataset = datasets.CIFAR10(root='data/',\n#                                      train=True,\n#                                      transform=train_transform,\n#                                      download=True)\n\n# test_dataset = datasets.CIFAR10(root='data/',\n#                                     train=False,\n#                                     transform=test_transform,\n#                                     download=True)\n\nnum_classes = 100\ntrain_dataset = datasets.CIFAR100(root='data/',\n                                  train=True,\n                                  transform=train_transform,\n                                  download=True)\n\ntest_dataset = datasets.CIFAR100(root='data/',\n                                 train=False,\n                                 transform=test_transform,\n                                 download=True)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True,\n                                           pin_memory=True,\n                                           num_workers=2)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False,\n                                          pin_memory=True,\n                                          num_workers=2)\n\nimport math\nimport torch\nfrom torch.optim.optimizer import Optimizer, required\n\nclass RAdam(Optimizer):\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=False):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n        \n        self.degenerated_to_sgd = degenerated_to_sgd\n        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n            for param in params:\n                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n                    param['buffer'] = [[None, None, None] for _ in range(10)]\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError('RAdam does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state['step'] += 1\n                buffered = group['buffer'][int(state['step'] % 10)]\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it's an approximated value\n                    if N_sma >= 5:\n                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n                    elif self.degenerated_to_sgd:\n                        step_size = 1.0 / (1 - beta1 ** state['step'])\n                    else:\n                        step_size = -1\n                    buffered[2] = step_size\n\n                # more conservative since it's an approximated value\n                if N_sma >= 5:\n                    if group['weight_decay'] != 0:\n                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n                    p.data.copy_(p_data_fp32)\n                elif step_size > 0:\n                    if group['weight_decay'] != 0:\n                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n                    p.data.copy_(p_data_fp32)\n\n        return loss\ncnn = ResNet34(num_classes=num_classes)\ncnn = cnn.cuda()\ncriterion = nn.CrossEntropyLoss().cuda()\ncnn_optimizer = torch.optim.SGD(cnn.parameters(), lr=learning_rate,\n                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n# cnn_optimizer = RAdam(cnn.parameters())\nscheduler = MultiStepLR(cnn_optimizer, milestones=[60, 120, 160], gamma=0.2)\ndef test(loader):\n    cnn.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n    correct = 0.\n    total = 0.\n    for images, labels in loader:\n        images = images.cuda()\n        labels = labels.cuda()\n\n        with torch.no_grad():\n            pred = cnn(images)\n\n        pred = torch.max(pred.data, 1)[1]\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n\n    val_acc = correct / total\n    cnn.train()\n    return val_acc\nmax_test_acc = 0.0  # Initialize variable to track max test accuracy\n\nfor epoch in range(200):\n    xentropy_loss_avg = 0.\n    correct = 0.\n    total = 0.\n\n    progress_bar = tqdm(train_loader)\n    for i, (images, labels) in enumerate(progress_bar):\n        progress_bar.set_description('Epoch ' + str(epoch))\n\n        images = images.cuda()\n        labels = labels.cuda()\n\n        cnn.zero_grad()\n        pred = cnn(images)\n\n        xentropy_loss = criterion(pred, labels)\n        xentropy_loss.backward()\n        cnn_optimizer.step()\n\n        xentropy_loss_avg += xentropy_loss.item()\n\n        # Calculate running average of accuracy\n        pred = torch.max(pred.data, 1)[1]\n        total += labels.size(0)\n        correct += (pred == labels.data).sum().item()\n        accuracy = correct / total\n\n        progress_bar.set_postfix(\n            xentropy='%.4f' % (xentropy_loss_avg / (i + 1)),\n            acc='%.4f' % accuracy)\n        \n    xentropy = '%.4f' % (xentropy_loss_avg / (i + 1))\n    test_acc = test(test_loader)\n    \n    # Update max test accuracy if current is higher\n    if test_acc > max_test_acc:\n        max_test_acc = test_acc\n    \n    tqdm.write('test_acc: %.4f (max: %.4f)' % (test_acc, max_test_acc))\n\n    scheduler.step()  # Use this line for PyTorch >=1.4\n    print({\n        'epoch': str(epoch), \n        'train_acc': '%.4f' % accuracy, \n        'test_acc': '%.4f' % test_acc,\n        'xentropy': xentropy,\n        'max_test_acc': '%.4f' % max_test_acc\n    })","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}